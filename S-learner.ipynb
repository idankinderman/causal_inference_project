{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7812c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\idan\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\idan\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\idan\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "id": "f328fb36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T20:17:44.166232Z",
     "start_time": "2024-09-15T20:17:44.028410Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "ba9f0667",
   "metadata": {},
   "source": [
    "# S-Learner"
   ]
  },
  {
   "cell_type": "code",
   "id": "18358cfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T20:17:45.860981Z",
     "start_time": "2024-09-15T20:17:45.133736Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor  # Import MLPRegressor\n",
    "\n",
    "class S_learner:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, T_train, T_test, train_on_full_data=False):\n",
    "        # Validate data before initializing\n",
    "        inputs = [x_train, y_train, x_test, y_test, T_train, T_test]\n",
    "        for dataset in inputs:\n",
    "            self.check_nulls_in_dataframe(dataset)\n",
    "        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.T_train = T_train\n",
    "        self.T_test = T_test\n",
    "        self.train_on_full_data = train_on_full_data\n",
    "        self.models = {}\n",
    "        self.measures = {}\n",
    "\n",
    "    def fit(self):\n",
    "        x_train_full = self.x_train.copy()\n",
    "        x_train_full.loc[:, \"T\"] = self.T_train\n",
    "        y_train = self.y_train.copy()\n",
    "        \n",
    "        if self.train_on_full_data:\n",
    "            x_test_full = self.x_test.copy()\n",
    "            x_test_full.loc[:, \"T\"] = self.T_test\n",
    "            x_train_full = pd.concat([x_train_full, x_test_full], axis=0)\n",
    "            y_test = self.y_test.copy()\n",
    "            y_train = pd.concat([y_train, y_test], axis=0)\n",
    "                \n",
    "        self.models['linear_regression'] = LinearRegression()\n",
    "        self.models['linear_regression'].fit(x_train_full, y_train)\n",
    "        print(\"Fitted Linear Regression\")\n",
    "\n",
    "        self.models['svr_rbf'] = SVR(kernel='rbf')\n",
    "        self.models['svr_rbf'].fit(x_train_full, y_train)\n",
    "        print(\"Fitted SVR with RBF kernel\")\n",
    "\n",
    "        self.models['svr_poly'] = SVR(kernel='poly', degree=2)\n",
    "        self.models['svr_poly'].fit(x_train_full, y_train)\n",
    "        print(\"Fitted SVR with Polynomial kernel\")\n",
    "\n",
    "        self.models['gradient_boosting'] = GradientBoostingRegressor()\n",
    "        self.models['gradient_boosting'].fit(x_train_full, y_train)\n",
    "        print(\"Fitted Gradient Boosting Regressor\")\n",
    "\n",
    "        self.models['random_forest'] = RandomForestRegressor()\n",
    "        self.models['random_forest'].fit(x_train_full, y_train)\n",
    "        print(\"Fitted RandomForest Regressor\")\n",
    "        \n",
    "        self.models['mlp'] = MLPRegressor(hidden_layer_sizes=(192,), max_iter=1500, activation='relu', \n",
    "                                          solver='adam', learning_rate_init=0.00005, random_state=42)\n",
    "        self.models['mlp'].fit(x_train_full, y_train)\n",
    "        print(\"Fitted MLP Regressor\")\n",
    "        \n",
    "\n",
    "    def evaluate(self):\n",
    "        x_train_full = self.x_train.copy()\n",
    "        x_test_full = self.x_test.copy()\n",
    "        \n",
    "        x_train_full.loc[:, \"T\"] = self.T_train\n",
    "        x_test_full.loc[:, \"T\"] = self.T_test\n",
    "        \n",
    "        results = {}\n",
    "        for name, model in self.models.items():\n",
    "            train_pred = model.predict(x_train_full)\n",
    "            test_pred = model.predict(x_test_full)\n",
    "            train_mse = mean_squared_error(self.y_train, train_pred)\n",
    "            test_mse = mean_squared_error(self.y_test, test_pred)\n",
    "            results[name] = {'Train MSE': train_mse, 'Test MSE': test_mse}\n",
    "        \n",
    "        for name, scores in results.items():\n",
    "            print(f\"{name}: Train MSE = {scores['Train MSE']:.4f}, Test MSE = {scores['Test MSE']:.4f}\")\n",
    "    \n",
    "    def compute_ATE(self, with_prints=True):\n",
    "        x_combined = pd.concat([self.x_train, self.x_test], axis=0)\n",
    "        self.compute_effect(x=x_combined, measure_name='ATE', with_prints=with_prints)\n",
    "    \n",
    "    def compute_ATE_final(self, list_of_models):\n",
    "        final_ATE = 0\n",
    "        for model in list_of_models:\n",
    "            final_ATE += self.measures['ATE'][model]\n",
    "        final_ATE = final_ATE / len(list_of_models)\n",
    "        print(\"\\nFinal ATE:\", final_ATE)\n",
    "        return final_ATE\n",
    "        \n",
    "    def compute_effect(self, x, measure_name, with_prints=True):\n",
    "        self.measures[measure_name] = {}\n",
    "        \n",
    "        x_with_T_zero = x.copy()\n",
    "        x_with_T_zero['T'] = 0\n",
    "\n",
    "        x_with_T_one = x.copy()\n",
    "        x_with_T_one['T'] = 1\n",
    "        \n",
    "        for key in self.models:\n",
    "            predictions_one = self.models[key].predict(x_with_T_one)\n",
    "            predictions_zero = self.models[key].predict(x_with_T_zero)\n",
    "            diffrences = predictions_one - predictions_zero\n",
    "            self.measures[measure_name][key] = np.mean(diffrences)\n",
    "        \n",
    "        if with_prints:\n",
    "            print()\n",
    "            print(f\"The {measure_name} are \", self.measures[measure_name])\n",
    "            print()\n",
    "               \n",
    "    \n",
    "    def check_nulls_in_dataframe(self, df):\n",
    "        # Check if there are any null values in the DataFrame\n",
    "        if df.isnull().any().any():\n",
    "            print(\"The DataFrame contains null values.\")\n",
    "            # Count of nulls in each column\n",
    "            null_counts = df.isnull().sum()\n",
    "            print(\"Count of null values in each column:\")\n",
    "            print(null_counts[null_counts > 0])\n",
    "        else:\n",
    "            print(\"The DataFrame does not contain any null values.\")\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "f9806a4a",
   "metadata": {},
   "source": [
    "# T-Learner"
   ]
  },
  {
   "cell_type": "code",
   "id": "4eb6ea3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T20:17:45.949599Z",
     "start_time": "2024-09-15T20:17:45.926756Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor  # Import MLPRegressor\n",
    "\n",
    "class T_learner:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, T_train, T_test, train_on_full_data=False):\n",
    "        # Validate data before initializing\n",
    "        inputs = [x_train, y_train, x_test, y_test, T_train, T_test]\n",
    "        for dataset in inputs:\n",
    "            self.check_nulls_in_dataframe(dataset)\n",
    "        \n",
    "        treated_indices_train = T_train == 1\n",
    "        treated_indices_test = T_test == 1\n",
    "        \n",
    "        # x\n",
    "        self.x = {'train': {}, 'test': {}}\n",
    "        self.x['train'][0] = x_train[~treated_indices_train]\n",
    "        self.x['train'][1] = x_train[treated_indices_train]\n",
    "        self.x['test'][0] = x_test[~treated_indices_test]\n",
    "        self.x['test'][1] = x_test[treated_indices_test]\n",
    "        \n",
    "        # y\n",
    "        self.y = {'train': {}, 'test': {}}\n",
    "        self.y['train'][0] = y_train[~treated_indices_train]\n",
    "        self.y['train'][1] = y_train[treated_indices_train]\n",
    "        self.y['test'][0] = y_test[~treated_indices_test]\n",
    "        self.y['test'][1] = y_test[treated_indices_test]\n",
    "        \n",
    "        # else\n",
    "        self.train_on_full_data = train_on_full_data\n",
    "        self.models = {0:{}, 1:{}}\n",
    "        self.measures = {}\n",
    "        \n",
    "\n",
    "    def fit(self):\n",
    "        for T in [0,1]:\n",
    "            print(f\"\\nFitting models with T = {T}\")\n",
    "            \n",
    "            x_train_full = self.x['train'][T].copy()\n",
    "            y_train = self.y['train'][T].copy()\n",
    "\n",
    "            if self.train_on_full_data:\n",
    "                x_test_full = self.x['test'][T].copy()\n",
    "                x_train_full = pd.concat([x_train_full, x_test_full], axis=0)\n",
    "                y_test = self.y['test'][T].copy()\n",
    "                y_train = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "            self.models[T]['linear_regression'] = LinearRegression()\n",
    "            self.models[T]['linear_regression'].fit(x_train_full, y_train)\n",
    "            print(\"Fitted Linear Regression\")\n",
    "\n",
    "            self.models[T]['svr_rbf'] = SVR(kernel='rbf')\n",
    "            self.models[T]['svr_rbf'].fit(x_train_full, y_train)\n",
    "            print(\"Fitted SVR with RBF kernel\")\n",
    "\n",
    "            self.models[T]['svr_poly'] = SVR(kernel='poly', degree=2)\n",
    "            self.models[T]['svr_poly'].fit(x_train_full, y_train)\n",
    "            print(\"Fitted SVR with Polynomial kernel\")\n",
    "\n",
    "            self.models[T]['gradient_boosting'] = GradientBoostingRegressor()\n",
    "            self.models[T]['gradient_boosting'].fit(x_train_full, y_train)\n",
    "            print(\"Fitted Gradient Boosting Regressor\")\n",
    "\n",
    "            self.models[T]['random_forest'] = RandomForestRegressor()\n",
    "            self.models[T]['random_forest'].fit(x_train_full, y_train)\n",
    "            print(\"Fitted RandomForest Regressor\")\n",
    "\n",
    "            self.models[T]['mlp'] = MLPRegressor(hidden_layer_sizes=(192,), max_iter=1500, activation='relu', \n",
    "                                          solver='adam', learning_rate_init=0.00005, random_state=42)\n",
    "            self.models[T]['mlp'].fit(x_train_full, y_train)\n",
    "            print(\"Fitted MLP Regressor\")\n",
    "        \n",
    "\n",
    "    def evaluate(self):\n",
    "        results = {0 : {}, 1 : {}}\n",
    "        for T in [0,1]:\n",
    "            x_train_full = self.x['train'][T].copy()\n",
    "            x_test_full = self.x['test'][T].copy()\n",
    "\n",
    "            for name, model in self.models[T].items():\n",
    "                train_pred = model.predict(x_train_full)\n",
    "                test_pred = model.predict(x_test_full)\n",
    "                train_mse = mean_squared_error(self.y['train'][T], train_pred)\n",
    "                test_mse = mean_squared_error(self.y['test'][T], test_pred)\n",
    "                results[T][name] = {'Train MSE': train_mse, 'Test MSE': test_mse}\n",
    "        \n",
    "        for T in [0,1]: \n",
    "            for name, scores in results[T].items():\n",
    "                print(f\"T: {T} | {name}: Train MSE = {scores['Train MSE']:.4f}, Test MSE = {scores['Test MSE']:.4f}\")\n",
    "    \n",
    "    def compute_ATE(self, with_prints=True):\n",
    "        x_combined = pd.concat([self.x['train'][0], self.x['train'][1], self.x['test'][0], self.x['test'][1]], axis=0)\n",
    "        self.compute_effect(x=x_combined, measure_name='ATE', with_prints=with_prints)\n",
    "    \n",
    "    def compute_ATE_final(self, list_of_models):\n",
    "        final_ATE = 0\n",
    "        for model in list_of_models:\n",
    "            final_ATE += self.measures['ATE'][model]\n",
    "        final_ATE = final_ATE / len(list_of_models)\n",
    "        print(\"\\nFinal ATE:\", final_ATE)\n",
    "        return final_ATE\n",
    "        \n",
    "    def compute_effect(self, x, measure_name, with_prints=True):\n",
    "        self.measures[measure_name] = {}\n",
    "        \n",
    "        for key in self.models[0]:\n",
    "            predictions_one = self.models[1][key].predict(x)\n",
    "            predictions_zero = self.models[0][key].predict(x)\n",
    "            diffrences = predictions_one - predictions_zero\n",
    "            #print(f\"{measure_name}, diffrences for {key}:\", diffrences)\n",
    "            self.measures[measure_name][key] = np.mean(diffrences)\n",
    "        \n",
    "        if with_prints:\n",
    "            print()\n",
    "            print(f\"The {measure_name} are \", self.measures[measure_name])\n",
    "            print()\n",
    "               \n",
    "    \n",
    "    def check_nulls_in_dataframe(self, df):\n",
    "        # Check if there are any null values in the DataFrame\n",
    "        if df.isnull().any().any():\n",
    "            print(\"The DataFrame contains null values.\")\n",
    "            # Count of nulls in each column\n",
    "            null_counts = df.isnull().sum()\n",
    "            print(\"Count of null values in each column:\")\n",
    "            print(null_counts[null_counts > 0])\n",
    "        else:\n",
    "            print(\"The DataFrame does not contain any null values.\")\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "a463939a",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "id": "d302be9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T20:17:46.725661Z",
     "start_time": "2024-09-15T20:17:46.712860Z"
    }
   },
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class Matching:\n",
    "    def __init__(self, x, y, T):\n",
    "        self.x = x.copy()\n",
    "        self.y = y.copy()\n",
    "        self.T = T.copy()\n",
    "        # Splitting the data based on T\n",
    "        self.x1 = x[T == 1].reset_index(drop=True)\n",
    "        self.y1 = y[T == 1].reset_index(drop=True)\n",
    "        self.x0 = x[T == 0].reset_index(drop=True)\n",
    "        self.y0 = y[T == 0].reset_index(drop=True)\n",
    "        \n",
    "        self.ATE = {}\n",
    "        self.ATT = {}\n",
    "\n",
    "    def compute_ATE(self, k):\n",
    "        # Ensure k is a positive integer\n",
    "        if k <= 0 or not isinstance(k, int):\n",
    "            raise ValueError(\"k must be a positive integer\")\n",
    "        \n",
    "        # Initialize the nearest neighbors models\n",
    "        nn_0 = NearestNeighbors(n_neighbors=k)\n",
    "        nn_1 = NearestNeighbors(n_neighbors=k)\n",
    "        \n",
    "        nn_0.fit(self.x0.values)\n",
    "        nn_1.fit(self.x1.values)\n",
    "        \n",
    "        # Calculate CAT for T=1\n",
    "        CAT_1 = []\n",
    "        for i, xi in self.x1.iterrows():\n",
    "            _, indices = nn_0.kneighbors([xi.values])\n",
    "            y_neighbors = self.y0.iloc[indices[0]]\n",
    "            CAT_1.append(self.y1.loc[i] - y_neighbors.mean())\n",
    "\n",
    "        # Calculate CAT for T=0\n",
    "        CAT_0 = []\n",
    "        for i, xi in self.x0.iterrows():\n",
    "            _, indices = nn_1.kneighbors([xi.values])\n",
    "            y_neighbors = self.y1.iloc[indices[0]]\n",
    "            CAT_0.append(y_neighbors.mean() - self.y0.loc[i])\n",
    "\n",
    "        # Calculate and return ATE\n",
    "        all_CAT = CAT_1 + CAT_0\n",
    "        self.ATE[k] = np.mean(all_CAT)\n",
    "        print(f\"ATE for k = {k} : {self.ATE[k]}\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "409537b9",
   "metadata": {},
   "source": [
    "# Young, no children"
   ]
  },
  {
   "cell_type": "code",
   "id": "7456eccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T20:18:01.460189Z",
     "start_time": "2024-09-15T20:18:01.448307Z"
    }
   },
   "source": [
    "with open('./preprocessed_data/df_young_no_children_dict.pickle', 'rb') as f:\n",
    "    df_young_no_children_dict = pickle.load(f)\n",
    "\n",
    "for key in df_young_no_children_dict:\n",
    "    print(key, df_young_no_children_dict[key].shape)\n",
    "\n",
    "threshold = 2\n",
    "df_young_no_children_dict['T_train'] = df_young_no_children_dict['T_train'].apply(lambda x: 0 if x <= threshold else 1)\n",
    "df_young_no_children_dict['T_test'] = df_young_no_children_dict['T_test'].apply(lambda x: 0 if x <= threshold else 1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_normalized (1591, 97)\n",
      "X_test_normalized (281, 97)\n",
      "Y_train (1591,)\n",
      "Y_test (281,)\n",
      "T_train (1591,)\n",
      "T_test (281,)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T20:18:03.476865Z",
     "start_time": "2024-09-15T20:18:03.466261Z"
    }
   },
   "cell_type": "code",
   "source": "df_young_no_children_dict['Y_train']",
   "id": "f414b23b9ee07db8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       4\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "1586    2\n",
       "1587    1\n",
       "1588    3\n",
       "1589    2\n",
       "1590    3\n",
       "Name: # BIO CHILDREN REPORTED, Length: 1591, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "144db651",
   "metadata": {},
   "source": [
    "### s-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb0489d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "linear_regression: Train MSE = 1.7393, Test MSE = 3121135964352433241456640.0000\n",
      "svr_rbf: Train MSE = 1.4127, Test MSE = 2.1832\n",
      "svr_poly: Train MSE = 1.4298, Test MSE = 2.2454\n",
      "gradient_boosting: Train MSE = 1.3942, Test MSE = 2.1804\n",
      "random_forest: Train MSE = 0.2786, Test MSE = 2.1812\n",
      "mlp: Train MSE = 0.4767, Test MSE = 2.5022\n",
      "\n",
      "The ATE are  {'linear_regression': 0.0855716803135016, 'svr_rbf': 0.08173014394129184, 'svr_poly': 0.00583226934077547, 'gradient_boosting': 0.03563232264890556, 'random_forest': 0.05887286324786324, 'mlp': 0.0996685064526924}\n",
      "\n",
      "\n",
      "Final ATE: 0.06897595907268826\n"
     ]
    }
   ],
   "source": [
    "s_learner_young_no_children = S_learner(x_train=df_young_no_children_dict['X_train_normalized'], \n",
    "                      y_train=df_young_no_children_dict['Y_train'], \n",
    "                      x_test=df_young_no_children_dict['X_test_normalized'],\n",
    "                      y_test=df_young_no_children_dict['Y_test'],\n",
    "                      T_train=df_young_no_children_dict['T_train'],\n",
    "                      T_test=df_young_no_children_dict['T_test'])\n",
    "\n",
    "s_learner_young_no_children.fit()\n",
    "s_learner_young_no_children.evaluate()\n",
    "s_learner_young_no_children.compute_ATE()\n",
    "_ = s_learner_young_no_children.compute_ATE_final(['svr_rbf', 'gradient_boosting', 'random_forest', 'mlp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3e09b",
   "metadata": {},
   "source": [
    "### t-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed6e6541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "\n",
      "Fitting models with T = 0\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "\n",
      "Fitting models with T = 1\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "T: 0 | linear_regression: Train MSE = 1.6339, Test MSE = 2432753395077570138996736.0000\n",
      "T: 0 | svr_rbf: Train MSE = 1.3076, Test MSE = 1.6435\n",
      "T: 0 | svr_poly: Train MSE = 1.3001, Test MSE = 1.6442\n",
      "T: 0 | gradient_boosting: Train MSE = 1.2119, Test MSE = 1.6899\n",
      "T: 0 | random_forest: Train MSE = 0.2765, Test MSE = 1.5896\n",
      "T: 0 | mlp: Train MSE = 0.3872, Test MSE = 2.0440\n",
      "T: 1 | linear_regression: Train MSE = 1.7328, Test MSE = 2013389047060483919870689280.0000\n",
      "T: 1 | svr_rbf: Train MSE = 1.3986, Test MSE = 3.0785\n",
      "T: 1 | svr_poly: Train MSE = 1.4122, Test MSE = 3.2042\n",
      "T: 1 | gradient_boosting: Train MSE = 1.1119, Test MSE = 3.3940\n",
      "T: 1 | random_forest: Train MSE = 0.2954, Test MSE = 3.2934\n",
      "T: 1 | mlp: Train MSE = 0.5252, Test MSE = 3.7379\n",
      "\n",
      "The ATE are  {'linear_regression': 3518195482422.8013, 'svr_rbf': 0.2707701616161646, 'svr_poly': 0.24632254178976506, 'gradient_boosting': 0.12951836030500222, 'random_forest': 0.10128205128205128, 'mlp': 0.13467215900461355}\n",
      "\n",
      "\n",
      "Final ATE: 0.15906068305195792\n"
     ]
    }
   ],
   "source": [
    "t_learner_df_young_no_children = T_learner(x_train=df_young_no_children_dict['X_train_normalized'], \n",
    "                      y_train=df_young_no_children_dict['Y_train'], \n",
    "                      x_test=df_young_no_children_dict['X_test_normalized'],\n",
    "                      y_test=df_young_no_children_dict['Y_test'],\n",
    "                      T_train=df_young_no_children_dict['T_train'],\n",
    "                      T_test=df_young_no_children_dict['T_test'])\n",
    "\n",
    "t_learner_df_young_no_children.fit()\n",
    "t_learner_df_young_no_children.evaluate()\n",
    "t_learner_df_young_no_children.compute_ATE()\n",
    "_ = t_learner_df_young_no_children.compute_ATE_final(['svr_rbf', 'gradient_boosting', 'random_forest', 'mlp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb976f30",
   "metadata": {},
   "source": [
    "### matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5cc6789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for k = 1 : 0.22382478632478633\n",
      "ATE for k = 3 : 0.1898148148148148\n",
      "ATE for k = 5 : 0.18782051282051282\n",
      "ATE for k = 9 : 0.18209876543209877\n",
      "ATE for k = 15 : 0.1772792022792023\n",
      "ATE for k = 50 : 0.19371794871794873\n"
     ]
    }
   ],
   "source": [
    "matching_df_young_no_children = Matching(x=pd.concat([df_young_no_children_dict['X_train_normalized'].reset_index(drop=True), df_young_no_children_dict['X_test_normalized'].reset_index(drop=True)], axis=0),\n",
    "                     y=pd.concat([df_young_no_children_dict['Y_train'].reset_index(drop=True), df_young_no_children_dict['Y_test'].reset_index(drop=True)], axis=0),\n",
    "                     T=pd.concat([df_young_no_children_dict['T_train'], df_young_no_children_dict['T_test']], axis=0))\n",
    "\n",
    "matching_df_young_no_children.compute_ATE(1)\n",
    "matching_df_young_no_children.compute_ATE(3)\n",
    "matching_df_young_no_children.compute_ATE(5)\n",
    "matching_df_young_no_children.compute_ATE(9)\n",
    "matching_df_young_no_children.compute_ATE(15)\n",
    "matching_df_young_no_children.compute_ATE(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db81711",
   "metadata": {},
   "source": [
    "# Mature, no children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99aed23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_normalized (1256, 93)\n",
      "X_test_normalized (222, 93)\n",
      "Y_train (1256,)\n",
      "Y_test (222,)\n",
      "T_train (1256,)\n",
      "T_test (222,)\n"
     ]
    }
   ],
   "source": [
    "with open('df_mature_no_children_dict.pickle', 'rb') as f:\n",
    "    df_mature_no_children_dict = pickle.load(f)\n",
    "\n",
    "for key in df_young_no_children_dict:\n",
    "    print(key, df_mature_no_children_dict[key].shape)\n",
    "\n",
    "threshold = 2\n",
    "df_mature_no_children_dict['T_train'] = df_mature_no_children_dict['T_train'].apply(lambda x: 0 if x <= threshold else 1)\n",
    "df_mature_no_children_dict['T_test'] = df_mature_no_children_dict['T_test'].apply(lambda x: 0 if x <= threshold else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2ea17",
   "metadata": {},
   "source": [
    "### s-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97982b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "linear_regression: Train MSE = 1.4152, Test MSE = 38713129794933195014144.0000\n",
      "svr_rbf: Train MSE = 1.1050, Test MSE = 1.8404\n",
      "svr_poly: Train MSE = 1.1164, Test MSE = 1.9354\n",
      "gradient_boosting: Train MSE = 1.1491, Test MSE = 1.7347\n",
      "random_forest: Train MSE = 0.2221, Test MSE = 1.7637\n",
      "mlp: Train MSE = 0.2999, Test MSE = 2.3847\n",
      "\n",
      "The ATE are  {'linear_regression': 0.18460078878234945, 'svr_rbf': 0.07764656932449003, 'svr_poly': 0.0056766361526181764, 'gradient_boosting': 0.08976166312302018, 'random_forest': 0.07942489851150203, 'mlp': 0.10186885315376218}\n",
      "\n",
      "\n",
      "Final ATE: 0.0871754960281936\n"
     ]
    }
   ],
   "source": [
    "s_learner_mature_no_children = S_learner(x_train=df_mature_no_children_dict['X_train_normalized'], \n",
    "                      y_train=df_mature_no_children_dict['Y_train'], \n",
    "                      x_test=df_mature_no_children_dict['X_test_normalized'],\n",
    "                      y_test=df_mature_no_children_dict['Y_test'],\n",
    "                      T_train=df_mature_no_children_dict['T_train'],\n",
    "                      T_test=df_mature_no_children_dict['T_test'])\n",
    "\n",
    "s_learner_mature_no_children.fit()\n",
    "s_learner_mature_no_children.evaluate()\n",
    "s_learner_mature_no_children.compute_ATE()\n",
    "_ = s_learner_mature_no_children.compute_ATE_final(['svr_rbf', 'gradient_boosting', 'random_forest', 'mlp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8629eb28",
   "metadata": {},
   "source": [
    "### t-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c12fdfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "\n",
      "Fitting models with T = 0\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "\n",
      "Fitting models with T = 1\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "T: 0 | linear_regression: Train MSE = 1.3012, Test MSE = 176867084656900840108326912.0000\n",
      "T: 0 | svr_rbf: Train MSE = 0.9950, Test MSE = 1.8766\n",
      "T: 0 | svr_poly: Train MSE = 0.9907, Test MSE = 1.9281\n",
      "T: 0 | gradient_boosting: Train MSE = 1.0236, Test MSE = 1.8589\n",
      "T: 0 | random_forest: Train MSE = 0.2170, Test MSE = 1.8541\n",
      "T: 0 | mlp: Train MSE = 0.2213, Test MSE = 2.4112\n",
      "T: 1 | linear_regression: Train MSE = 1.4105, Test MSE = 1852155952696930955662721024.0000\n",
      "T: 1 | svr_rbf: Train MSE = 1.1146, Test MSE = 1.4887\n",
      "T: 1 | svr_poly: Train MSE = 1.0744, Test MSE = 1.5752\n",
      "T: 1 | gradient_boosting: Train MSE = 0.8716, Test MSE = 1.6661\n",
      "T: 1 | random_forest: Train MSE = 0.2413, Test MSE = 1.7045\n",
      "T: 1 | mlp: Train MSE = 0.2619, Test MSE = 2.2909\n",
      "\n",
      "The ATE are  {'linear_regression': 2831750159435.3564, 'svr_rbf': 0.1869374979536639, 'svr_poly': 0.22930162133879478, 'gradient_boosting': 0.17368177382689085, 'random_forest': 0.17094722598105547, 'mlp': 0.10818375225112814}\n",
      "\n",
      "\n",
      "Final ATE: 0.15906068305195792\n"
     ]
    }
   ],
   "source": [
    "t_learner_mature_no_children = T_learner(x_train=df_mature_no_children_dict['X_train_normalized'], \n",
    "                      y_train=df_mature_no_children_dict['Y_train'], \n",
    "                      x_test=df_mature_no_children_dict['X_test_normalized'],\n",
    "                      y_test=df_mature_no_children_dict['Y_test'],\n",
    "                      T_train=df_mature_no_children_dict['T_train'],\n",
    "                      T_test=df_mature_no_children_dict['T_test'])\n",
    "\n",
    "t_learner_mature_no_children.fit()\n",
    "t_learner_mature_no_children.evaluate()\n",
    "t_learner_mature_no_children.compute_ATE()\n",
    "_ = t_learner_df_young_no_children.compute_ATE_final(['svr_rbf', 'gradient_boosting', 'random_forest', 'mlp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c98f8",
   "metadata": {},
   "source": [
    "### matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c8f6666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for k = 1 : 0.2780784844384303\n",
      "ATE for k = 3 : 0.24515110509697793\n",
      "ATE for k = 5 : 0.23315290933694183\n",
      "ATE for k = 9 : 0.23372425199218164\n",
      "ATE for k = 15 : 0.24023455119530898\n",
      "ATE for k = 50 : 0.24376184032476322\n"
     ]
    }
   ],
   "source": [
    "matching_mature_no_children = Matching(x=pd.concat([df_mature_no_children_dict['X_train_normalized'].reset_index(drop=True), df_mature_no_children_dict['X_test_normalized'].reset_index(drop=True)], axis=0),\n",
    "                     y=pd.concat([df_mature_no_children_dict['Y_train'].reset_index(drop=True), df_mature_no_children_dict['Y_test'].reset_index(drop=True)], axis=0),\n",
    "                     T=pd.concat([df_mature_no_children_dict['T_train'], df_mature_no_children_dict['T_test']], axis=0))\n",
    "\n",
    "matching_mature_no_children.compute_ATE(1)\n",
    "matching_mature_no_children.compute_ATE(3)\n",
    "matching_mature_no_children.compute_ATE(5)\n",
    "matching_mature_no_children.compute_ATE(9)\n",
    "matching_mature_no_children.compute_ATE(15)\n",
    "matching_mature_no_children.compute_ATE(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7eea5c",
   "metadata": {},
   "source": [
    "# Mature, with children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09978027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_normalized (460, 82)\n",
      "X_test_normalized (82, 82)\n",
      "Y_train (460,)\n",
      "Y_test (82,)\n",
      "T_train (460,)\n",
      "T_test (82,)\n"
     ]
    }
   ],
   "source": [
    "with open('df_mature_with_children_dict.pickle', 'rb') as f:\n",
    "    df_mature_with_children_dict = pickle.load(f)\n",
    "\n",
    "for key in df_mature_with_children_dict:\n",
    "    print(key, df_mature_with_children_dict[key].shape)\n",
    "\n",
    "threshold = 2\n",
    "df_mature_with_children_dict['T_train'] = df_mature_with_children_dict['T_train'].apply(lambda x: 0 if x <= threshold else 1)\n",
    "df_mature_with_children_dict['T_test'] = df_mature_with_children_dict['T_test'].apply(lambda x: 0 if x <= threshold else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d156a0c7",
   "metadata": {},
   "source": [
    "### s-learner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8ba05f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "linear_regression: Train MSE = 1.2246, Test MSE = 58081881843523414654976.0000\n",
      "svr_rbf: Train MSE = 0.9753, Test MSE = 2.5108\n",
      "svr_poly: Train MSE = 1.0456, Test MSE = 2.6612\n",
      "gradient_boosting: Train MSE = 0.6733, Test MSE = 2.4924\n",
      "random_forest: Train MSE = 0.2179, Test MSE = 2.6054\n",
      "mlp: Train MSE = 0.3364, Test MSE = 2.7386\n",
      "\n",
      "The ATE are  {'linear_regression': 0.2433473931907288, 'svr_rbf': 0.05985493576233995, 'svr_poly': 0.004449037556042961, 'gradient_boosting': 0.06512305003700121, 'random_forest': 0.13470479704797048, 'mlp': 0.1014327708222044}\n",
      "\n",
      "\n",
      "Final ATE: 0.090278888417379\n"
     ]
    }
   ],
   "source": [
    "s_learner_mature_with_children = S_learner(x_train=df_mature_with_children_dict['X_train_normalized'], \n",
    "                      y_train=df_mature_with_children_dict['Y_train'], \n",
    "                      x_test=df_mature_with_children_dict['X_test_normalized'],\n",
    "                      y_test=df_mature_with_children_dict['Y_test'],\n",
    "                      T_train=df_mature_with_children_dict['T_train'],\n",
    "                      T_test=df_mature_with_children_dict['T_test'])\n",
    "\n",
    "s_learner_mature_with_children.fit()\n",
    "s_learner_mature_with_children.evaluate()\n",
    "s_learner_mature_with_children.compute_ATE()\n",
    "_ = s_learner_mature_with_children.compute_ATE_final(['svr_rbf', 'gradient_boosting', 'random_forest', 'mlp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ec9e3",
   "metadata": {},
   "source": [
    "### t-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5547cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "The DataFrame does not contain any null values.\n",
      "\n",
      "Fitting models with T = 0\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "\n",
      "Fitting models with T = 1\n",
      "Fitted Linear Regression\n",
      "Fitted SVR with RBF kernel\n",
      "Fitted SVR with Polynomial kernel\n",
      "Fitted Gradient Boosting Regressor\n",
      "Fitted RandomForest Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Idan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted MLP Regressor\n",
      "T: 0 | linear_regression: Train MSE = 0.8996, Test MSE = 2340197915879636683718656.0000\n",
      "T: 0 | svr_rbf: Train MSE = 0.7297, Test MSE = 2.8617\n",
      "T: 0 | svr_poly: Train MSE = 0.7078, Test MSE = 3.0380\n",
      "T: 0 | gradient_boosting: Train MSE = 0.3640, Test MSE = 3.1521\n",
      "T: 0 | random_forest: Train MSE = 0.1794, Test MSE = 2.9553\n",
      "T: 0 | mlp: Train MSE = 0.2229, Test MSE = 3.3425\n",
      "T: 1 | linear_regression: Train MSE = 1.1260, Test MSE = 14494535059815162745867730944.0000\n",
      "T: 1 | svr_rbf: Train MSE = 1.0580, Test MSE = 1.9187\n",
      "T: 1 | svr_poly: Train MSE = 1.2484, Test MSE = 2.0536\n",
      "T: 1 | gradient_boosting: Train MSE = 0.3548, Test MSE = 2.2106\n",
      "T: 1 | random_forest: Train MSE = 0.2699, Test MSE = 1.8323\n",
      "T: 1 | mlp: Train MSE = 0.3991, Test MSE = 2.2422\n",
      "\n",
      "The ATE are  {'linear_regression': 7355349974780.64, 'svr_rbf': 0.5114343025331958, 'svr_poly': 0.5551432471321722, 'gradient_boosting': 0.30124083173016875, 'random_forest': 0.3122509225092251, 'mlp': 0.24033011734063342}\n",
      "\n",
      "\n",
      "Final ATE: 0.34131404352830574\n"
     ]
    }
   ],
   "source": [
    "t_learner_mature_with_children = T_learner(x_train=df_mature_with_children_dict['X_train_normalized'], \n",
    "                      y_train=df_mature_with_children_dict['Y_train'], \n",
    "                      x_test=df_mature_with_children_dict['X_test_normalized'],\n",
    "                      y_test=df_mature_with_children_dict['Y_test'],\n",
    "                      T_train=df_mature_with_children_dict['T_train'],\n",
    "                      T_test=df_mature_with_children_dict['T_test'])\n",
    "\n",
    "t_learner_mature_with_children.fit()\n",
    "t_learner_mature_with_children.evaluate()\n",
    "t_learner_mature_with_children.compute_ATE()\n",
    "_ = t_learner_mature_with_children.compute_ATE_final(['svr_rbf', 'gradient_boosting', 'random_forest', 'mlp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8567e51",
   "metadata": {},
   "source": [
    "### matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac0f526f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for k = 1 : 0.48154981549815495\n",
      "ATE for k = 3 : 0.42988929889298894\n",
      "ATE for k = 5 : 0.4612546125461255\n",
      "ATE for k = 9 : 0.45202952029520294\n",
      "ATE for k = 15 : 0.4253382533825339\n",
      "ATE for k = 50 : 0.45845018450184505\n"
     ]
    }
   ],
   "source": [
    "matching_mature_with_children = Matching(x=pd.concat([df_mature_with_children_dict['X_train_normalized'].reset_index(drop=True), df_mature_with_children_dict['X_test_normalized'].reset_index(drop=True)], axis=0),\n",
    "                     y=pd.concat([df_mature_with_children_dict['Y_train'].reset_index(drop=True), df_mature_with_children_dict['Y_test'].reset_index(drop=True)], axis=0),\n",
    "                     T=pd.concat([df_mature_with_children_dict['T_train'], df_mature_with_children_dict['T_test']], axis=0))\n",
    "\n",
    "matching_mature_with_children.compute_ATE(1)\n",
    "matching_mature_with_children.compute_ATE(3)\n",
    "matching_mature_with_children.compute_ATE(5)\n",
    "matching_mature_with_children.compute_ATE(9)\n",
    "matching_mature_with_children.compute_ATE(15)\n",
    "matching_mature_with_children.compute_ATE(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b7db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
